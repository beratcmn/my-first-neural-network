{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the credits goes to Sebastian Lague.\n",
    "[His video](https://www.youtube.com/watch?v=hfMk-kjRv4c&t=189s&ab_channel=SebastianLague)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Idea\n",
    "\n",
    "### We are trying to understand if an imaginary fruit is poisonous or not by their spike and spot sizes.\n",
    "\n",
    "### There will be 2 inputs for spike and spot and 2 outputs poisonous or non-poisonous\n",
    "\n",
    "### If output1 > output2 then its non-poisonous otherwise its poisonous\n",
    "\n",
    "<!-- ![](../assets/ss-1.png) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we are trying to create a simple network as shown below\n",
    "\n",
    "<img src=\"../assets/ss-1.png\" height=\"300\">\n",
    "\n",
    "! Model below does not scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight values connect each input to each output.\n",
    "weight_1_1: float\n",
    "weight_2_1: float\n",
    "\n",
    "weight_1_2: float\n",
    "weight_2_2: float\n",
    "\n",
    "# Bias values\n",
    "bias_1: float\n",
    "bias_2: float\n",
    "\n",
    "\n",
    "def Classify(input_1: float, input_2: float) -> int:\n",
    "    global weight_1_1\n",
    "    global weight_2_1\n",
    "    global weight_1_2\n",
    "    global weight_2_2\n",
    "    global bias_1\n",
    "    global bias_2\n",
    "\n",
    "    output_1: float = (input_1 * weight_1_1) + (input_2 * weight_2_1) + bias_1\n",
    "    output_2: float = (input_1 * weight_1_2) + (input_2 * weight_2_2) + bias_2\n",
    "\n",
    "    return 0 if output_1 > output_2 else 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Hidden Layers\n",
    "\n",
    "<img src=\"../assets/ss-2.png\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are just doing Linear Regression. We need an Activation Function in order to get a weighted input between 0 - 1\n",
    "\n",
    "#### Here is a simple Activation Function.\n",
    "<img src=\"../assets/ss-3.png\" height=\"300\">\n",
    "\n",
    "#### Here is a more complex one. (Sigmoid Function)\n",
    "<img src=\"../assets/ss-4.png\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataclasses import dataclass\n",
    "from typing import List\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sigmoid Function](https://en.wikipedia.org/wiki/Sigmoid_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def ActivationFunction(weightedInput: float) -> float:\n",
    "    return 1 / (1 + math.exp(-weightedInput))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will implement a Gradiant Cost method.\n",
    "-- Add Further info here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    numNodesIn: int\n",
    "    numNodesOut: int\n",
    "    costGradientW: List[List[float]]\n",
    "    costGradientB: List[float]\n",
    "    weights: List[List[float]]\n",
    "    biases: List[float]\n",
    "\n",
    "    def __init__(self, numNodesIn: int, numNodesOut: int):\n",
    "        self.numNodesIn = numNodesIn\n",
    "        self.numNodesOut = numNodesOut\n",
    "\n",
    "        self.weights = [[0.0 for i in range(numNodesOut)] for j in range(numNodesIn)]\n",
    "        self.biases = [0.0 for i in range(numNodesOut)]\n",
    "\n",
    "        self.InitializeRandomWeights()\n",
    "\n",
    "    def InitializeRandomWeights(self):\n",
    "        for nodeIn in range(self.numNodesIn):\n",
    "            for nodeOut in range(self.numNodesOut):\n",
    "                randomValue = random.random() * -1\n",
    "                self.weights[nodeIn][nodeOut] = randomValue / math.sqrt(self.numNodesIn)\n",
    "\n",
    "    def CalculateOutputs(self, inputs: List[float]) -> List[float]:\n",
    "        activations: List[float]\n",
    "\n",
    "        for nodeOut in range(self.numNodesOut):\n",
    "            weightedInput = self.biases[nodeOut]\n",
    "\n",
    "            for nodeIn in range(self.numNodesIn):\n",
    "                weightedInput += inputs[nodeIn] * self.weights[nodeIn][nodeOut]\n",
    "\n",
    "            activations[nodeOut] = ActivationFunction(weightedInput)\n",
    "\n",
    "        return activations\n",
    "\n",
    "    def NodeCost(outputActivation: float, expectedOutput: float) -> float:\n",
    "        error = outputActivation - expectedOutput\n",
    "        return error * error\n",
    "\n",
    "    def ApplyGradients(self, learningRate: float):\n",
    "        for nodeOut in range(self.numNodesOut):\n",
    "            self.biases[nodeOut] -= self.costGradientB[nodeOut] * learningRate\n",
    "\n",
    "            for nodeIn in range(self.numNodesIn):\n",
    "                self.weights[nodeIn][nodeOut] -= self.costGradientW[nodeIn][nodeOut] * learningRate\n",
    "\n",
    "    def NodeCostDerivative(outputActivation: float, expectedOutput: float) -> float:\n",
    "        return 2 * (outputActivation - expectedOutput)\n",
    "\n",
    "    def ActivationDerivative(weightedInput: float) -> float:\n",
    "        activation = ActivationFunction(weightedInput)\n",
    "        return activation * (1 - activation)\n",
    "\n",
    "    def CalculateOutputLayerNodeValues(self, expectedOutputs: List[float]) -> float:\n",
    "        nodeValues: List[float]\n",
    "\n",
    "        for i in range(len(expectedOutputs)):\n",
    "            costDerivative = self.NodeCostDerivative(self.activations[i], expectedOutputs[i])\n",
    "            activationDerivative = self.ActivationDerivative(self.weightedInputs[i])\n",
    "            nodeValues[i] = costDerivative * activationDerivative\n",
    "\n",
    "        return nodeValues\n",
    "\n",
    "    def UpdateGradients(self, nodeValues: List[float]):\n",
    "        for nodeOut in range(self.numNodesOut):\n",
    "            for nodeIn in range(self.numNodesIn):\n",
    "                self.costGradientW[nodeIn][nodeOut] += self.inputs[nodeIn] * nodeValues[nodeOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    layers: List[Layer]\n",
    "\n",
    "    def __init__(self, layerSizes: List[int]):\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(len(layerSizes) - 1):\n",
    "            self.layers.append(Layer(layerSizes[i], layerSizes[i + 1]))\n",
    "\n",
    "    def CalculateOutputs(self, inputs: List[float]) -> List[float]:\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.CalculateOutputs(inputs)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def Classify(self, inputs: List[float]) -> int:\n",
    "        outputs = self.CalculateOutputs(inputs)\n",
    "        return 0 if outputs[0] > outputs[1] else 1\n",
    "\n",
    "    def CalculateCost(self, inputs: List[float], expectedOutputs: List[float]) -> float:\n",
    "        outputs = self.CalculateOutputs(inputs)\n",
    "        outputLayer: Layer = self.layers[-1]\n",
    "        cost = 0.0\n",
    "\n",
    "        for nodeOut in range(len(outputs)):\n",
    "            cost += outputLayer.NodeCost(outputs[nodeOut], expectedOutputs[nodeOut])\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def Learn(self, inputs: List[float], expectedOutputs: List[float], learningRate: float):\n",
    "        h: float = 0.0001\n",
    "        originalCost: float = self.CalculateCost(inputs, expectedOutputs)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            for nodeIn in range(layer.numNodesIn):\n",
    "                for nodeOut in range(layer.numNodesOut):\n",
    "                    layer.weights[nodeIn][nodeOut] += h\n",
    "                    deltaCost = self.CalculateCost(inputs, expectedOutputs) - originalCost\n",
    "                    layer.weights[nodeIn][nodeOut] -= h\n",
    "                    layer.costGradientW[nodeIn][nodeOut] = deltaCost / h\n",
    "\n",
    "            for biasIndex in range(len(layer.biases)):\n",
    "                layer.biases[biasIndex] += h\n",
    "                deltaCost = self.CalculateCost(inputs, expectedOutputs) - originalCost\n",
    "                layer.biases[biasIndex] -= h\n",
    "                layer.costGradientB[biasIndex] = deltaCost / h\n",
    "\n",
    "        for layer in self.layers:\n",
    "            layer.ApplyGradients(learningRate)\n",
    "\n",
    "    def UpdateAllGradients(self, inputs: List[float], expectedOutputs: List[float]):\n",
    "        self.CalculateOutputs(inputs)\n",
    "\n",
    "        outputLayer: Layer = self.layers[-1]\n",
    "        nodeValues = outputLayer.Cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork([2, 3, 2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25621a6444091dc14910ee41a6267b1d2768c84cc926468623f73e767ef4d0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
